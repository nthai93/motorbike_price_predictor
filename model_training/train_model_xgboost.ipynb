{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8454f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ DATA_PATH: c:\\Users\\User\\Desktop\\motorbike_project\\output_datasets\\motorbike_final_dataset_clean.csv\n",
      "âœ… Dataset loaded: 7,208 rows Ã— 15 columns\n",
      "âœ… Found existing 'Log_Gia' column.\n",
      "âœ… Found existing 'Log_So_Km_da_di' column.\n",
      "âœ… Added mean price features: Brand_mean_price, Dong_mean_price, Segment_mean_price\n",
      "âœ… Scaled numeric features\n",
      "ðŸ“Š Train: (5757, 16), Test: (1440, 16)\n",
      "ðŸ” Cross-validated RÂ²: 0.400 Â± 0.063\n",
      "\n",
      "ðŸ“ˆ Final Model Performance (V3 â€“ Extended Features)\n",
      "   MAE  = 9,430,795 VND\n",
      "   RMSE = 21,833,939 VND\n",
      "   RÂ²   = 0.678\n",
      "ðŸ’¾ Model saved â†’ c:\\Users\\User\\Desktop\\motorbike_project\\output_datasets\\best_model_XGBoost.pkl\n",
      "ðŸ’¾ Scaler saved â†’ c:\\Users\\User\\Desktop\\motorbike_project\\output_datasets\\scaler_XGBoost.pkl\n",
      "ðŸŽ¯ Training finished successfully â€“ Version 3 Enhanced!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸï¸ TRAIN MODEL V3 â€“ MOTORBIKE PRICE PREDICTOR (with mean stats & region)\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# ============================================================\n",
    "# 1ï¸âƒ£ Setup paths\n",
    "# ============================================================\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "OUTPUT_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\", \"output_datasets\"))\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DATA_PATH = os.path.join(OUTPUT_DIR, \"motorbike_final_dataset_clean.csv\")\n",
    "print(f\"ðŸ“„ DATA_PATH: {DATA_PATH}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2ï¸âƒ£ Load data\n",
    "# ============================================================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"âœ… Dataset loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "# Basic cleaning\n",
    "df = df[(df[\"Gia\"] > 0) & (df[\"Gia\"] < 5e8)]\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"Gia\", \"Tuoi_xe\"])\n",
    "\n",
    "# Use existing logs\n",
    "if \"Log_Gia\" in df.columns:\n",
    "    print(\"âœ… Found existing 'Log_Gia' column.\")\n",
    "else:\n",
    "    df[\"Log_Gia\"] = np.log1p(df[\"Gia\"])\n",
    "    print(\"â„¹ï¸ Created new 'Log_Gia' from raw price.\")\n",
    "\n",
    "if \"Log_So_Km_da_di\" in df.columns:\n",
    "    print(\"âœ… Found existing 'Log_So_Km_da_di' column.\")\n",
    "else:\n",
    "    raise KeyError(\"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t Log_So_Km_da_di trong dataset.\")\n",
    "\n",
    "# ============================================================\n",
    "# 3ï¸âƒ£ Feature construction\n",
    "# ============================================================\n",
    "df[\"Tuoi_xe_x_Km\"] = df[\"Tuoi_xe\"] * df[\"Log_So_Km_da_di\"]\n",
    "df[\"Km_moi_nam\"] = np.expm1(df[\"Log_So_Km_da_di\"]) / (df[\"Tuoi_xe\"] + 0.1)\n",
    "\n",
    "# âœ… Mean price per groups (statistical features)\n",
    "df[\"Brand_mean_price\"] = df[\"Thuong_hieu_code\"].map(df.groupby(\"Thuong_hieu_code\")[\"Log_Gia\"].mean().to_dict())\n",
    "df[\"Dong_mean_price\"] = df[\"Dong_xe_code\"].map(df.groupby(\"Dong_xe_code\")[\"Log_Gia\"].mean().to_dict())\n",
    "df[\"Segment_mean_price\"] = df[\"Phan_khuc_dung_tich_code\"].map(df.groupby(\"Phan_khuc_dung_tich_code\")[\"Log_Gia\"].mean().to_dict())\n",
    "\n",
    "print(\"âœ… Added mean price features: Brand_mean_price, Dong_mean_price, Segment_mean_price\")\n",
    "\n",
    "# ============================================================\n",
    "# 4ï¸âƒ£ Feature list (bá»• sung vÃ¹ng miá»n)\n",
    "# ============================================================\n",
    "FEATURES = [\n",
    "    \"Tuoi_xe\",\n",
    "    \"Log_So_Km_da_di\",\n",
    "    \"Km_moi_nam\",\n",
    "    \"Tuoi_xe_x_Km\",\n",
    "    \"TinhTrang_x_XuatXu\",\n",
    "    \"LoaiXe_x_PhanKhuc\",\n",
    "    \"Thuong_hieu_code\",\n",
    "    \"Dong_xe_code\",\n",
    "    \"Loai_xe_code\",\n",
    "    \"Tinh_trang_code\",\n",
    "    \"Xuat_xu_code\",\n",
    "    \"Phan_khuc_dung_tich_code\",\n",
    "    \"Vung_mien_code\",                 # âœ… vÃ¹ng miá»n\n",
    "    \"Brand_mean_price\",               # âœ… trung bÃ¬nh thÆ°Æ¡ng hiá»‡u\n",
    "    \"Dong_mean_price\",                # âœ… trung bÃ¬nh dÃ²ng xe\n",
    "    \"Segment_mean_price\"              # âœ… trung bÃ¬nh phÃ¢n khÃºc\n",
    "]\n",
    "TARGET = \"Log_Gia\"\n",
    "\n",
    "# Check missing\n",
    "missing = [c for c in FEATURES if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"âš ï¸ Dataset missing columns: {missing}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5ï¸âƒ£ Scale numeric features\n",
    "# ============================================================\n",
    "scale_cols = [\"Tuoi_xe\", \"Log_So_Km_da_di\", \"Km_moi_nam\", \"Tuoi_xe_x_Km\"]\n",
    "scaler = StandardScaler()\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "print(\"âœ… Scaled numeric features\")\n",
    "\n",
    "# ============================================================\n",
    "# 6ï¸âƒ£ Train-test split\n",
    "# ============================================================\n",
    "X, y = df[FEATURES], df[TARGET]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"ðŸ“Š Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7ï¸âƒ£ Model definition (fine-tuned)\n",
    "# ============================================================\n",
    "params = {\n",
    "    \"n_estimators\": 1200,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 8,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.85,\n",
    "    \"gamma\": 0.15,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"reg_alpha\": 0.4,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"reg:squarederror\"\n",
    "}\n",
    "model = XGBRegressor(**params)\n",
    "\n",
    "# ============================================================\n",
    "# 8ï¸âƒ£ Cross-validation\n",
    "# ============================================================\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "r2_scores = cross_val_score(model, X, y, cv=cv, scoring=\"r2\")\n",
    "print(f\"ðŸ” Cross-validated RÂ²: {r2_scores.mean():.3f} Â± {r2_scores.std():.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 9ï¸âƒ£ Train & Evaluate\n",
    "# ============================================================\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_true_vnd, y_pred_vnd = np.expm1(y_test), np.expm1(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(y_true_vnd, y_pred_vnd)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_vnd, y_pred_vnd))\n",
    "r2 = r2_score(y_true_vnd, y_pred_vnd)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Final Model Performance (V3 â€“ Extended Features)\")\n",
    "print(f\"   MAE  = {mae:,.0f} VND\")\n",
    "print(f\"   RMSE = {rmse:,.0f} VND\")\n",
    "print(f\"   RÂ²   = {r2:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ” Feature Importance\n",
    "# ============================================================\n",
    "xgb.plot_importance(model, importance_type=\"gain\", max_num_features=15)\n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"feature_importance_v3.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ’¾ Save model & scaler\n",
    "# ============================================================\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, \"best_model_XGBoost.pkl\")\n",
    "SCALER_PATH = os.path.join(OUTPUT_DIR, \"scaler_XGBoost.pkl\")\n",
    "\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "print(f\"ðŸ’¾ Model saved â†’ {MODEL_PATH}\")\n",
    "print(f\"ðŸ’¾ Scaler saved â†’ {SCALER_PATH}\")\n",
    "print(\"ðŸŽ¯ Training finished successfully â€“ Version 3 Enhanced!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3923bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ DATA_PATH: c:\\Users\\User\\Desktop\\motorbike_project\\output_datasets\\motorbike_final_dataset_clean.csv\n",
      "âœ… Dataset loaded: 7,208 rows Ã— 15 columns\n",
      "['Gia', 'Log_Gia', 'Tuoi_xe', 'Log_So_Km_da_di', 'Km_moi_nam', 'Tuoi_xe_x_Km', 'TinhTrang_x_XuatXu', 'LoaiXe_x_PhanKhuc', 'Vung_mien_code', 'Thuong_hieu_code', 'Dong_xe_code', 'Loai_xe_code', 'Tinh_trang_code', 'Xuat_xu_code', 'Phan_khuc_dung_tich_code']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "OUTPUT_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\", \"output_datasets\"))\n",
    "MAPPING_DIR = os.path.abspath(os.path.join(BASE_DIR, \"..\", \"mappings\"))\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DATA_PATH = os.path.join(OUTPUT_DIR, \"motorbike_final_dataset_clean.csv\")\n",
    "print(f\"ðŸ“„ DATA_PATH: {DATA_PATH}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2ï¸âƒ£ Load data\n",
    "# ============================================================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"âœ… Dataset loaded: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(df.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark311 (Data Science)",
   "language": "python",
   "name": "pyspark311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
