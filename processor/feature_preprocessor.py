import pandas as pd
import numpy as np
import re
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib, json, os

class FeaturePreprocessor:
    def __init__(self):
        os.makedirs("mappings", exist_ok=True)
        os.makedirs("output_datasets", exist_ok=True)

    def clean_and_transform(self, df):
        df = df.copy()

        # ============================================================
        # 1Ô∏è‚É£ L√†m s·∫°ch c∆° b·∫£n
        # ============================================================
        df["Gia"] = (
            df["Gi√°"]
            .astype(str)
            .str.replace(r"[^0-9]", "", regex=True)
            .replace("", np.nan)
            .astype(float)
        )
        df["Nam_dang_ky"] = pd.to_numeric(df["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
        df["So_Km_da_di"] = pd.to_numeric(df["S·ªë Km ƒë√£ ƒëi"], errors="coerce")

        df = df.dropna(subset=["Gia"])
        df.fillna({
            "Th∆∞∆°ng hi·ªáu": "Kh√¥ng r√µ",
            "D√≤ng xe": "Kh√¥ng r√µ",
            "T√¨nh tr·∫°ng": "Kh√¥ng r√µ",
            "Lo·∫°i xe": "Kh√¥ng r√µ",
            "Xu·∫•t x·ª©": "Kh√¥ng r√µ",
            "Ph√¢n kh√∫c dung t√≠ch": "Kh√¥ng r√µ"
        }, inplace=True)

        # ============================================================
        # 2Ô∏è‚É£ T·∫°o c√°c feature c∆° b·∫£n
        # ============================================================
        df["Tuoi_xe"] = 2025 - df["Nam_dang_ky"]
        df["Log_So_Km_da_di"] = np.log1p(df["So_Km_da_di"])
        df["Log_Gia"] = np.log1p(df["Gia"])
        df["Km_moi_nam"] = df["So_Km_da_di"] / (df["Tuoi_xe"] + 0.1)
        df["Gia_tren_km"] = df["Gia"] / (df["So_Km_da_di"] + 1)
        df["Tuoi_xe_x_Km"] = df["Tuoi_xe"] * df["Log_So_Km_da_di"]

        # ============================================================
        # 3Ô∏è‚É£ M√£ h√≥a bi·∫øn ph√¢n lo·∫°i
        # ============================================================
        cat_cols = ["Th∆∞∆°ng hi·ªáu","Lo·∫°i xe","T√¨nh tr·∫°ng","Xu·∫•t x·ª©","Ph√¢n kh√∫c dung t√≠ch"]
        for col in cat_cols:
            le = LabelEncoder()
            df[col + "_code"] = le.fit_transform(df[col].astype(str))
            json.dump(
                dict(zip(le.classes_, le.transform(le.classes_))),
                open(f"mappings/{col.lower()}.json", "w", encoding="utf-8"),
                ensure_ascii=False, indent=2
            )

        # ============================================================
        # 4Ô∏è‚É£ Feature t∆∞∆°ng t√°c
        # ============================================================
        df["TinhTrang_x_XuatXu"] = df["T√¨nh tr·∫°ng_code"] * df["Xu·∫•t x·ª©_code"]
        df["LoaiXe_x_PhanKhuc"] = df["Lo·∫°i xe_code"] * df["Ph√¢n kh√∫c dung t√≠ch_code"]

        # ============================================================
        # 5Ô∏è‚É£ Mean price features (m·ªõi cho v3/v4)
        # ============================================================
        df["Brand_mean_price"] = df["Th∆∞∆°ng hi·ªáu_code"].map(
            df.groupby("Th∆∞∆°ng hi·ªáu_code")["Log_Gia"].mean().to_dict()
        )
        df["Dong_mean_price"] = df["D√≤ng xe"].map(
            df.groupby("D√≤ng xe")["Log_Gia"].mean().to_dict()
        )
        df["Segment_mean_price"] = df["Ph√¢n kh√∫c dung t√≠ch_code"].map(
            df.groupby("Ph√¢n kh√∫c dung t√≠ch_code")["Log_Gia"].mean().to_dict()
        )

        # Fill NaN b·∫±ng mean to√†n c·ª•c
        global_mean = df["Log_Gia"].mean()
        df[["Brand_mean_price", "Dong_mean_price", "Segment_mean_price"]] = (
            df[["Brand_mean_price", "Dong_mean_price", "Segment_mean_price"]]
            .fillna(global_mean)
        )

        # ============================================================
        # 6Ô∏è‚É£ Scale numeric features
        # ============================================================
        scale_cols = ["Tuoi_xe", "Log_So_Km_da_di", "Km_moi_nam", "Tuoi_xe_x_Km"]
        scaler = StandardScaler()
        df[scale_cols] = scaler.fit_transform(df[scale_cols])
        joblib.dump(scaler, "output_datasets/scaler_XGBoost.pkl")

        # ============================================================
        # 7Ô∏è‚É£ Xu·∫•t file k·∫øt qu·∫£
        # ============================================================
        output_path = "output_datasets/motorbike_user_input_clean.csv"
        df.to_csv(output_path, index=False)
        print(f"üíæ Saved cleaned dataset ‚Üí {output_path}")

        return df
